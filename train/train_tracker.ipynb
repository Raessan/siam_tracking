{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322ce283-943e-4b01-9e3f-5275cb1e9e45",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "from src.dataset_lasot import DatasetLaSOT\n",
    "from src.model import SiameseTracker\n",
    "from src.loss import compute_loss\n",
    "from src.draw_samples_training import draw_samples_training\n",
    "import config.config as cfg\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import copy\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5fb52-84c9-4b5a-9061-e8e452ba790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "################ LOAD ALL THE PARAMETERS #############################\n",
    "# DATASET PARAMETERS\n",
    "DIR_DATA = cfg.DIR_DATA # Root to the folder with the prepared data\n",
    "SIZE_TEMPLATE = cfg.SIZE_TEMPLATE\n",
    "SIZE_SEARCH = cfg.SIZE_SEARCH\n",
    "SIZE_OUT = cfg.SIZE_OUT\n",
    "MAX_FRAME_SEP = cfg.MAX_FRAME_SEP\n",
    "NEG_PROB = cfg.NEG_PROB\n",
    "EXTRA_CONTEXT_TEMPLATE = cfg.EXTRA_CONTEXT_TEMPLATE\n",
    "MIN_EXTRA_CONTEXT_SEARCH = cfg.MIN_EXTRA_CONTEXT_SEARCH\n",
    "MAX_EXTRA_CONTEXT_SEARCH = cfg.MAX_EXTRA_CONTEXT_SEARCH\n",
    "MAX_SHIFT = cfg.MAX_SHIFT\n",
    "REG_FULL = cfg.REG_FULL\n",
    "IMG_AUGMENT_TRAINING = cfg.IMG_AUGMENT_TRAINING\n",
    "IMG_AUGMENT_VALID = cfg.IMG_AUGMENT_VALID\n",
    "IMG_MEAN = cfg.IMG_MEAN\n",
    "IMG_STD = cfg.IMG_STD\n",
    "    \n",
    "# MODEL PARAMETERS\n",
    "BATCH_SIZE = cfg.BATCH_SIZE\n",
    "LAYERS_FREEZE = cfg.LAYERS_FREEZE\n",
    "\n",
    "# TRAINING PARAMETERS\n",
    "THRESHOLD_CLS = cfg.THRESHOLD_CLS\n",
    "ALPHA_LOSS = cfg.ALPHA_LOSS\n",
    "GAMMA_LOSS = cfg.GAMMA_LOSS \n",
    "WEIGHT_LOSS = cfg.WEIGHT_LOSS\n",
    "\n",
    "LEARNING_RATE = cfg.LEARNING_RATE\n",
    "NUM_EPOCHS = cfg.NUM_EPOCHS\n",
    "NUM_SAMPLES_PLOT = cfg.NUM_SAMPLES_PLOT\n",
    "\n",
    "LOAD_MODEL = cfg.LOAD_MODEL\n",
    "SAVE_MODEL = cfg.SAVE_MODEL\n",
    "MODEL_PATH_TRAIN_LOAD = cfg.MODEL_PATH_TRAIN_LOAD\n",
    "RESULTS_PATH = cfg.RESULTS_PATH\n",
    "\n",
    "train_set = DatasetLaSOT(\"train\", DIR_DATA, SIZE_TEMPLATE, SIZE_SEARCH, SIZE_OUT, MAX_FRAME_SEP, \n",
    "                                 NEG_PROB, EXTRA_CONTEXT_TEMPLATE, MIN_EXTRA_CONTEXT_SEARCH, MAX_EXTRA_CONTEXT_SEARCH, MAX_SHIFT, REG_FULL,\n",
    "                                IMG_AUGMENT_TRAINING, IMG_MEAN, IMG_STD)\n",
    "train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_set = DatasetLaSOT(\"val\", DIR_DATA, SIZE_TEMPLATE, SIZE_SEARCH, SIZE_OUT, MAX_FRAME_SEP, \n",
    "                                 NEG_PROB, EXTRA_CONTEXT_TEMPLATE, MIN_EXTRA_CONTEXT_SEARCH, MAX_EXTRA_CONTEXT_SEARCH, MAX_SHIFT, REG_FULL,\n",
    "                                  IMG_AUGMENT_VALID, IMG_MEAN, IMG_STD)\n",
    "val_dataloader = DataLoader(val_set, batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = SiameseTracker(SIZE_TEMPLATE, SIZE_SEARCH, SIZE_OUT, REG_FULL).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Load model\n",
    "if LOAD_MODEL:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH_TRAIN_LOAD))\n",
    "    print(\"Model successfully loaded!\")\n",
    "\n",
    "# Freeze parameters\n",
    "if LAYERS_FREEZE > 0:\n",
    "    children_backbone = list(model.backbone.named_children())\n",
    "    # 2) Take the first N names\n",
    "    to_freeze = [name for name, _ in children_backbone[:LAYERS_FREEZE]]\n",
    "    print(\"Freezing:\", to_freeze)\n",
    "    \n",
    "    # 3) Freeze all parameters whose name starts with those modules\n",
    "    for name, param in model.backbone.named_parameters():\n",
    "        if any(name.startswith(layer) for layer in to_freeze):\n",
    "            param.requires_grad = False\n",
    "\n",
    "n_params = sum([p.numel() for p in model.parameters()])\n",
    "print(\"Total number of parameters: \", n_params)\n",
    "n_trainable_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "print(\"Total number of trainable parameters: \", n_trainable_params)\n",
    "n_params_backbone = sum([p.numel() for p in model.backbone.parameters()])\n",
    "print(\"Number parameters backbone: \", n_params_backbone)\n",
    "n_params_cross_attn = sum([p.numel() for p in model.cross_attn.parameters()])\n",
    "print(\"Number parameters cross attn: \", n_params_cross_attn)\n",
    "n_params_cls = sum([p.numel() for p in model.cls_head.parameters()])\n",
    "print(\"Number parameters classification: \", n_params_cls)\n",
    "n_params_reg = sum([p.numel() for p in model.reg_head.parameters()])\n",
    "print(\"Number parameters regression: \", n_params_reg)\n",
    "\n",
    "if SAVE_MODEL:\n",
    "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    folder_path = f\"{RESULTS_PATH}/{current_date}\"\n",
    "    \n",
    "    json_params = { \n",
    "        \"SIZE_TEMPLATE\" : SIZE_TEMPLATE, \n",
    "        \"SIZE_SEARCH\" : SIZE_SEARCH, \n",
    "        \"SIZE_OUT\" : SIZE_OUT, \n",
    "        \"MAX_FRAME_SEPT\" : MAX_FRAME_SEP,\n",
    "        \"NEG_PROB\" : NEG_PROB,\n",
    "        \"EXTRA_CONTEXT_TEMPLATE\" : EXTRA_CONTEXT_TEMPLATE,\n",
    "        \"MIN_EXTRA_CONTEXT_SEARCH\" : MIN_EXTRA_CONTEXT_SEARCH,\n",
    "        \"MAX_EXTRA_CONTEXT_SEARCH \" : MAX_EXTRA_CONTEXT_SEARCH,\n",
    "        \"MAX_SHIFT\" : MAX_SHIFT,\n",
    "        \"REG_FULL\" : REG_FULL,\n",
    "        \"IMG_AUGMENT_TRAINING\": IMG_AUGMENT_TRAINING,\n",
    "        \"IMG_AUGMENT_VALID\": IMG_AUGMENT_VALID,\n",
    "        \"THRESHOLD_CLS\" : THRESHOLD_CLS,\n",
    "        \"ALPHA_LOSS\" : ALPHA_LOSS,\n",
    "        \"GAMMA_LOSS\" : GAMMA_LOSS,\n",
    "        \"WEIGHT_LOSS\" : WEIGHT_LOSS,\n",
    "        \"LEARNING_RATE\" : LEARNING_RATE,\n",
    "        \"LOAD_MODEL\" : LOAD_MODEL,\n",
    "        \"MODEL_PATH_TRAIN_LOAD\" : MODEL_PATH_TRAIN_LOAD,\n",
    "        \"LAYERS_FREEZE\": LAYERS_FREEZE\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf7a5c-64ed-4284-b26e-4e894fed84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    ##################### TRAIN #######################\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (template, search, heatmap, bbox, video_template_name, video_search_name) in enumerate(tqdm(train_dataloader)):\n",
    "        template, search, heatmap, bbox = template.to(device, dtype=torch.float), search.to(device, dtype=torch.float), heatmap.to(device, dtype=torch.float), bbox.to(device, dtype=torch.float)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        pred_heatmap, pred_bbox = model(template, search)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = compute_loss(pred_heatmap, pred_bbox, heatmap, bbox, ALPHA_LOSS, GAMMA_LOSS, WEIGHT_LOSS)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss[0].backward()\n",
    "        \n",
    "        # Gradient clipping and Optimize\n",
    "        # clip all gradients to max norm 5.0\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss[0].item()\n",
    "\n",
    "        if (batch_idx % 1000 == 0 and batch_idx > 0):\n",
    "            print(f\"Epoch {epoch+1}, batch {batch_idx}, Loss: {train_loss/(batch_idx+1)}, cls loss: {loss[1].item()}, regression loss: {loss[2].item()}\")\n",
    "\n",
    "        if (batch_idx % 10000 == 0 and batch_idx > 0):\n",
    "            draw_samples_training(template, search, torch.sigmoid(pred_heatmap), pred_bbox, heatmap, bbox, train_set.mean, train_set.std, THRESHOLD_CLS, NUM_SAMPLES_PLOT, video_template_name, video_search_name)\n",
    "    \n",
    "    train_loss /= float(batch_idx+1)\n",
    "    \n",
    "    ##################### VALIDATION #######################\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_loss_cls = 0.0\n",
    "    val_loss_reg = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (template, search, heatmap, bbox, video_template_name, video_search_name) in enumerate(tqdm(val_dataloader)):\n",
    "            template, search, heatmap, bbox = template.to(device, dtype=torch.float), search.to(device, dtype=torch.float), heatmap.to(device, dtype=torch.float), bbox.to(device, dtype=torch.float)\n",
    "    \n",
    "            # Forward pass\n",
    "            pred_heatmap, pred_bbox = model(template, search)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = compute_loss(pred_heatmap, pred_bbox, heatmap, bbox, ALPHA_LOSS, GAMMA_LOSS, WEIGHT_LOSS)\n",
    "    \n",
    "            val_loss += loss[0].item()\n",
    "            val_loss_cls += loss[1].item()\n",
    "            val_loss_reg += loss[2].item()\n",
    "    \n",
    "            if (batch_idx == 0):\n",
    "                draw_samples_training(template, search, torch.sigmoid(pred_heatmap), pred_bbox, heatmap, bbox, train_set.mean, train_set.std, THRESHOLD_CLS, NUM_SAMPLES_PLOT, video_template_name, video_search_name)\n",
    "    \n",
    "        val_loss /= float(batch_idx+1)\n",
    "        val_loss_cls /= float(batch_idx+1)\n",
    "        val_loss_reg /= float(batch_idx+1)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss}, val loss NN total: {val_loss}, val loss CLS: {val_loss_cls},  val loss Reg: {val_loss_reg}\")\n",
    "\n",
    "        if SAVE_MODEL:\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            # Save model and params\n",
    "            json_params_epoch = json_params.copy()\n",
    "            json_params_epoch[\"epoch\"] = epoch\n",
    "            json_params_epoch[\"train_loss\"] = train_loss\n",
    "            json_params_epoch[\"val_loss\"] = val_loss\n",
    "            json_params_epoch[\"val_loss_cls\"] = val_loss_cls\n",
    "            json_params_epoch[\"val_loss_reg\"] = val_loss_reg\n",
    "            model_path = os.path.join(folder_path,f\"model_{epoch}.pth\")\n",
    "            json_path = os.path.join(folder_path,f\"params_{epoch}.json\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            with open(json_path, \"w\") as outfile:\n",
    "                json.dump(json_params_epoch, outfile)\n",
    "    \n",
    "print(\"Training finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
