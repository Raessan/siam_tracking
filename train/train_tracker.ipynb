{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ce283-943e-4b01-9e3f-5275cb1e9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_lasot import DatasetLaSOT\n",
    "from src.model import SiameseTrackerDino\n",
    "from src.loss import compute_loss\n",
    "from src.draw_samples_training import draw_samples_training\n",
    "import config.config as cfg\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import copy\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5fb52-84c9-4b5a-9061-e8e452ba790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "################ LOAD ALL THE PARAMETERS #############################\n",
    "# DATASET PARAMETERS\n",
    "DIR_DATA = cfg.DIR_DATA # Root to the folder with the prepared data\n",
    "SIZE_TEMPLATE = cfg.SIZE_TEMPLATE\n",
    "SIZE_SEARCH = cfg.SIZE_SEARCH\n",
    "SIZE_OUT = cfg.SIZE_OUT\n",
    "MAX_FRAME_SEP = cfg.MAX_FRAME_SEP\n",
    "NEG_PROB = cfg.NEG_PROB\n",
    "EXTRA_CONTEXT_TEMPLATE = cfg.EXTRA_CONTEXT_TEMPLATE\n",
    "MIN_EXTRA_CONTEXT_SEARCH = cfg.MIN_EXTRA_CONTEXT_SEARCH\n",
    "MAX_EXTRA_CONTEXT_SEARCH = cfg.MAX_EXTRA_CONTEXT_SEARCH\n",
    "MAX_SHIFT = cfg.MAX_SHIFT\n",
    "REG_FULL = cfg.REG_FULL\n",
    "PROB_AUGMENT_TRAINING = cfg.PROB_AUGMENT_TRAINING\n",
    "PROB_AUGMENT_VALID = cfg.PROB_AUGMENT_VALID\n",
    "IMG_MEAN = cfg.IMG_MEAN\n",
    "IMG_STD = cfg.IMG_STD\n",
    "    \n",
    "# MODEL PARAMETERS\n",
    "DINOV3_DIR = cfg.DINOV3_DIR\n",
    "DINO_MODEL = cfg.DINO_MODEL\n",
    "DINO_MODEL_PATH = cfg.DINO_MODEL_PATH\n",
    "BATCH_SIZE = cfg.BATCH_SIZE\n",
    "PROJ_DIM = cfg.PROJ_DIM\n",
    "MODEL_TO_NUM_LAYERS = cfg.MODEL_TO_NUM_LAYERS\n",
    "MODEL_TO_EMBED_DIM = cfg.MODEL_TO_EMBED_DIM\n",
    "N_LAYERS_UNFREEZE = cfg.N_LAYERS_UNFREEZE\n",
    "\n",
    "# TRAINING PARAMETERS\n",
    "THRESHOLD_CLS = cfg.THRESHOLD_CLS\n",
    "ALPHA_LOSS = cfg.ALPHA_LOSS\n",
    "GAMMA_LOSS = cfg.GAMMA_LOSS \n",
    "WEIGHT_LOSS = cfg.WEIGHT_LOSS\n",
    "\n",
    "LEARNING_RATE = cfg.LEARNING_RATE\n",
    "NUM_EPOCHS = cfg.NUM_EPOCHS\n",
    "NUM_SAMPLES_PLOT = cfg.NUM_SAMPLES_PLOT\n",
    "\n",
    "LOAD_MODEL = cfg.LOAD_MODEL\n",
    "SAVE_MODEL = cfg.SAVE_MODEL\n",
    "MODEL_PATH_TRAIN_LOAD = cfg.MODEL_PATH_TRAIN_LOAD\n",
    "RESULTS_PATH = cfg.RESULTS_PATH\n",
    "\n",
    "train_set = DatasetLaSOT(\"trainval\", DIR_DATA, SIZE_TEMPLATE, SIZE_SEARCH, SIZE_OUT, MAX_FRAME_SEP, \n",
    "                                 NEG_PROB, EXTRA_CONTEXT_TEMPLATE, MIN_EXTRA_CONTEXT_SEARCH, MAX_EXTRA_CONTEXT_SEARCH, MAX_SHIFT, REG_FULL,\n",
    "                                PROB_AUGMENT_TRAINING, IMG_MEAN, IMG_STD)\n",
    "train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, num_workers=8, shuffle=True)\n",
    "\n",
    "val_set = DatasetLaSOT(\"test\", DIR_DATA, SIZE_TEMPLATE, SIZE_SEARCH, SIZE_OUT, MAX_FRAME_SEP, \n",
    "                                 NEG_PROB, EXTRA_CONTEXT_TEMPLATE, MIN_EXTRA_CONTEXT_SEARCH, MAX_EXTRA_CONTEXT_SEARCH, MAX_SHIFT, REG_FULL,\n",
    "                                  PROB_AUGMENT_VALID, IMG_MEAN, IMG_STD)\n",
    "val_dataloader = DataLoader(val_set, batch_size = BATCH_SIZE, num_workers=8, shuffle=True)\n",
    "\n",
    "dino_model = torch.hub.load(\n",
    "        repo_or_dir=DINOV3_DIR,\n",
    "        model=\"dinov3_vits16plus\",\n",
    "        source=\"local\",\n",
    "        weights=DINO_MODEL_PATH\n",
    "    )\n",
    "n_layers_dino = MODEL_TO_NUM_LAYERS[DINO_MODEL]\n",
    "embed_dim = MODEL_TO_EMBED_DIM[DINO_MODEL]\n",
    "model = SiameseTrackerDino(dino_model = dino_model, n_layers_dino = n_layers_dino, embed_dim = embed_dim, out_size = SIZE_OUT, \n",
    "                            proj_dim = PROJ_DIM, reg_full = REG_FULL).to(device)\n",
    "\n",
    "#template_dummy = torch.randn(32,3,SIZE_TEMPLATE,SIZE_TEMPLATE).to(device)\n",
    "#search_dummy = torch.randn(32,3,SIZE_SEARCH,SIZE_SEARCH).to(device)\n",
    "#_ = model(template_dummy, search_dummy)  # triggers lazy proj init\n",
    "print(\"Model backbone: \")\n",
    "print(model.backbone)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Load model\n",
    "if LOAD_MODEL:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH_TRAIN_LOAD))\n",
    "    print(\"Model successfully loaded!\")\n",
    "\n",
    "\n",
    "# Freeze parameters\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Unfreeze parameters of the added proj layer\n",
    "#for p in model.backbone.proj.parameters():\n",
    "    #p.requires_grad = True\n",
    "\n",
    "# Unfreeze last N transformer blocks\n",
    "if N_LAYERS_UNFREEZE > 0:\n",
    "    # Unfreeze the last norm layer\n",
    "    for p in model.backbone.dino.norm.parameters():\n",
    "        p.requires_grad = True\n",
    "    for block in model.backbone.dino.blocks[-N_LAYERS_UNFREEZE:]:\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "n_params = sum([p.numel() for p in model.parameters()])\n",
    "print(\"Total number of parameters: \", n_params)\n",
    "n_trainable_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "print(\"Total number of trainable parameters: \", n_trainable_params)\n",
    "n_params_backbone = sum([p.numel() for p in model.backbone.parameters()])\n",
    "print(\"Number parameters backbone: \", n_params_backbone)\n",
    "n_params_cross_attn = sum([p.numel() for p in model.cross_attn.parameters()])\n",
    "print(\"Number parameters cross attn: \", n_params_cross_attn)\n",
    "n_params_cls = sum([p.numel() for p in model.cls_head.parameters()])\n",
    "print(\"Number parameters classification: \", n_params_cls)\n",
    "n_params_reg = sum([p.numel() for p in model.reg_head.parameters()])\n",
    "print(\"Number parameters regression: \", n_params_reg)\n",
    "\n",
    "if SAVE_MODEL:\n",
    "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    folder_path = f\"{RESULTS_PATH}/{current_date}\"\n",
    "    \n",
    "    json_params = { \n",
    "        \"SIZE_TEMPLATE\" : SIZE_TEMPLATE, \n",
    "        \"SIZE_SEARCH\" : SIZE_SEARCH, \n",
    "        \"SIZE_OUT\" : SIZE_OUT, \n",
    "        \"MAX_FRAME_SEPT\" : MAX_FRAME_SEP,\n",
    "        \"NEG_PROB\" : NEG_PROB,\n",
    "        \"EXTRA_CONTEXT_TEMPLATE\" : EXTRA_CONTEXT_TEMPLATE,\n",
    "        \"MIN_EXTRA_CONTEXT_SEARCH\" : MIN_EXTRA_CONTEXT_SEARCH,\n",
    "        \"MAX_EXTRA_CONTEXT_SEARCH \" : MAX_EXTRA_CONTEXT_SEARCH,\n",
    "        \"MAX_SHIFT\" : MAX_SHIFT,\n",
    "        \"REG_FULL\" : REG_FULL,\n",
    "        \"PROB_AUGMENT_TRAINING\": PROB_AUGMENT_TRAINING,\n",
    "        \"PROB_AUGMENT_VALID\": PROB_AUGMENT_VALID,\n",
    "        \"THRESHOLD_CLS\" : THRESHOLD_CLS,\n",
    "        \"ALPHA_LOSS\" : ALPHA_LOSS,\n",
    "        \"GAMMA_LOSS\" : GAMMA_LOSS,\n",
    "        \"WEIGHT_LOSS\" : WEIGHT_LOSS,\n",
    "        \"LEARNING_RATE\" : LEARNING_RATE,\n",
    "        \"LOAD_MODEL\" : LOAD_MODEL,\n",
    "        \"MODEL_PATH_TRAIN_LOAD\" : MODEL_PATH_TRAIN_LOAD,\n",
    "        \"DINO_MODEL\": DINO_MODEL,\n",
    "        \"PROJ_DIM\": PROJ_DIM,\n",
    "        \"N_LAYERS_UNFREEZE\": N_LAYERS_UNFREEZE\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf7a5c-64ed-4284-b26e-4e894fed84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    ##################### TRAIN #######################\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (template, search, heatmap, bbox, video_template_name, video_search_name) in enumerate(tqdm(train_dataloader)):\n",
    "        template, search, heatmap, bbox = template.to(device, dtype=torch.float), search.to(device, dtype=torch.float), heatmap.to(device, dtype=torch.float), bbox.to(device, dtype=torch.float)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        pred_heatmap, pred_bbox = model(template, search)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = compute_loss(pred_heatmap, pred_bbox, heatmap, bbox, ALPHA_LOSS, GAMMA_LOSS, WEIGHT_LOSS)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss[0].backward()\n",
    "        \n",
    "        # Gradient clipping and Optimize\n",
    "        # clip all gradients to max norm 5.0\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss[0].item()\n",
    "\n",
    "        if (batch_idx % 1000 == 0 and batch_idx > 0):\n",
    "            print(f\"Epoch {epoch+1}, batch {batch_idx}, Loss: {train_loss/(batch_idx+1)}, cls loss: {loss[1].item()}, regression loss: {loss[2].item()}\")\n",
    "\n",
    "        if (batch_idx % 10000 == 0 and batch_idx > 0):\n",
    "            draw_samples_training(template, search, torch.sigmoid(pred_heatmap), pred_bbox, heatmap, bbox, train_set.mean, train_set.std, THRESHOLD_CLS, NUM_SAMPLES_PLOT, video_template_name, video_search_name)\n",
    "    \n",
    "    train_loss /= float(batch_idx+1)\n",
    "    \n",
    "    ##################### VALIDATION #######################\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_loss_cls = 0.0\n",
    "    val_loss_reg = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (template, search, heatmap, bbox, video_template_name, video_search_name) in enumerate(tqdm(val_dataloader)):\n",
    "            template, search, heatmap, bbox = template.to(device, dtype=torch.float), search.to(device, dtype=torch.float), heatmap.to(device, dtype=torch.float), bbox.to(device, dtype=torch.float)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_heatmap, pred_bbox = model(template, search)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = compute_loss(pred_heatmap, pred_bbox, heatmap, bbox, ALPHA_LOSS, GAMMA_LOSS, WEIGHT_LOSS)\n",
    "    \n",
    "            val_loss += loss[0].item()\n",
    "            val_loss_cls += loss[1].item()\n",
    "            val_loss_reg += loss[2].item()\n",
    "    \n",
    "            if (batch_idx == 0):\n",
    "                draw_samples_training(template, search, torch.sigmoid(pred_heatmap), pred_bbox, heatmap, bbox, train_set.mean, train_set.std, THRESHOLD_CLS, NUM_SAMPLES_PLOT, video_template_name, video_search_name)\n",
    "    \n",
    "        val_loss /= float(batch_idx+1)\n",
    "        val_loss_cls /= float(batch_idx+1)\n",
    "        val_loss_reg /= float(batch_idx+1)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss}, val loss NN total: {val_loss}, val loss CLS: {val_loss_cls},  val loss Reg: {val_loss_reg}\")\n",
    "\n",
    "        if SAVE_MODEL:\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            # Save model and params\n",
    "            json_params_epoch = json_params.copy()\n",
    "            json_params_epoch[\"epoch\"] = epoch\n",
    "            json_params_epoch[\"train_loss\"] = train_loss\n",
    "            json_params_epoch[\"val_loss\"] = val_loss\n",
    "            json_params_epoch[\"val_loss_cls\"] = val_loss_cls\n",
    "            json_params_epoch[\"val_loss_reg\"] = val_loss_reg\n",
    "            model_path = os.path.join(folder_path,f\"model_{epoch}.pth\")\n",
    "            json_path = os.path.join(folder_path,f\"params_{epoch}.json\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            with open(json_path, \"w\") as outfile:\n",
    "                json.dump(json_params_epoch, outfile)\n",
    "    \n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f27b57-6568-4387-8309-b88476c74b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
